{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN with `dm_control`\n",
    "\n",
    "Here are some experiments using deep Q-Learning to solve simple continuous control tasks. I implemented [the original DQN](https://www.nature.com/articles/nature14236) and used it to solve several tasks in the [DeepMind Control Suite](https://arxiv.org/abs/1801.00690). The key innovations from DQN are:\n",
    "\n",
    "1. Maintain a replay buffer of experiences from which minibatches are randomly drawn during training. This decreases correlations in the training data, thereby reducing variance in the updates.\n",
    "2. Keep an additional Q network for calculating targets that is an 'outdated' version of the main Q network. Every `q_update_interval` updates the weights are copied from the main to the target q network. Updates are more stable because the target network is updated less frequently.\n",
    "\n",
    "Q-Learning takes the max across actions, which is not ideal for continuous action spaces. In this implementation the action space is discretized, such that each action dimension can take a value in `linspace(action_min, actions_max, action_grid)`, where `action_grid=2` for this demo. The full action space is the cartesian product of the vectors for each dimension.\n",
    "\n",
    "The demo is organized as follows:\n",
    "1. **setup**\n",
    "2. **solving tasks:** cartpole (balance+swingup), ball in cup, pendulum\n",
    "3. **double DQN:** I implement [Double Q-Learning](https://arxiv.org/abs/1509.06461) and test whether it increases the accuracy of action-value estimates.\n",
    "4. **encouraging exploration:** To increase exploration I used a simple trick to encourage optimism in the face of uncertainty. Namely, I pretrained the network to output optimistic action-values across the state-space, which encourages exploration in the early phases of learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
